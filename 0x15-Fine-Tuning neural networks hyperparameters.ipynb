{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86749273-920f-4189-b514-e2ee40b23336",
   "metadata": {},
   "source": [
    "# Fine Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79beebef-8662-4486-9e63-eec11cc15fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use GridSearchCV or RandomizedSearchCV to explore the hyperparameter space.\n",
    "# We'll need to wrap our Keras models in objects that mimic regular Scikit-learn Regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b8550e-b94b-4a36-bf2a-f6091dbada52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8a12cc-8656-4941-99d0-20100e3c296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full),(X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4dc6dc-d152-4b9e-88c0-8a85081af9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acd1f25d-ce60-4a81-94b4-e425967a7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a function that will build and compile a keras model, given a set of hyperparameters.\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    optimizer = hp.Choice(\"optimizer\", values=[\"sgd\", \"adam\"])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8044977-0230-4f01-b7d8-62d284de865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 35s]\n",
      "val_accuracy: 0.7570000290870667\n",
      "\n",
      "Best val_accuracy So Far: 0.8468000292778015\n",
      "Total elapsed time: 00h 03m 17s\n"
     ]
    }
   ],
   "source": [
    "# doing a basic random search:\n",
    "\n",
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=5, overwrite=True, directory=\"my_fashion_mnist\", project_name=\"my_rnd_search\", seed=42)\n",
    "\n",
    "random_search_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b153a2-abfe-4230-824f-d85eaef86c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnol\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Sequential name=sequential, built=True>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a055018-e52e-4ae9-a01a-1447714c7b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Sequential name=sequential, built=True>,\n",
       " <Sequential name=sequential, built=True>,\n",
       " <Sequential name=sequential, built=True>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7fa1756-b0f9-465c-b4b2-9376efa77faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden': 8,\n",
       " 'n_neurons': 37,\n",
       " 'learning_rate': 0.008547485565344062,\n",
       " 'optimizer': 'sgd'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_params = random_search_tuner.get_best_hyperparameters(num_trials=3)\n",
    "top3_params[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2e7f37b-0e64-4c84-aff7-664a49acd650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "n_hidden: 8\n",
      "n_neurons: 37\n",
      "learning_rate: 0.008547485565344062\n",
      "optimizer: sgd\n",
      "Score: 0.8468000292778015\n"
     ]
    }
   ],
   "source": [
    "# Getting the best trial from the RandomSearchOracle.\n",
    "\n",
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cafe4e59-c84e-4cf5-a164-71d1550b59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6984 - loss: 2385.3774\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7737 - loss: 1391.2427\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 1306.9091\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 1331.8324\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7957 - loss: 1241.5813\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7938 - loss: 1268.6241\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7969 - loss: 1238.6377\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7911 - loss: 1333.6084\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 1195.6710\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8002 - loss: 1187.1306\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5896 - loss: 6589.1606\n"
     ]
    }
   ],
   "source": [
    "# More training and evaluations.\n",
    "\n",
    "best_model.fit(X_train_full, y_train_full, epochs=10)\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b2272a5-9578-41ea-add3-52cdd4b12dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we may want to fine-tune the data preprocessing hyperparameters or model.fit() args such as the batch size.\n",
    "# The following buils the same model with the same hyperparameters but uses the Boolean \"normalize\" hyperparameter to control wether or not to \n",
    "# standardize the training data before fitting the model.\n",
    "\n",
    "class MyClassificationHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model =  build_model(hp)\n",
    "        if not isinstance(model, keras.models.Model):\n",
    "            raise ValueError(\"build_model function did not return a valid Keras model instance.\")\n",
    "        return model\n",
    "    def fit(self, hp, model, X, y, **kwargs):\n",
    "        if hp.Boolean(\"normalize\"):\n",
    "            norm_layer = tf.keras.layers.Normalization()\n",
    "            X = norm_layer(X)\n",
    "        return model.fit(X, y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c330b1ac-3788-422c-80fa-33420cc0e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can then pass an instance of this class to the tuner of our choice, instead of passing the build_model function.\n",
    "\n",
    "hyperband_tuner = kt.Hyperband(\n",
    "    MyClassificationHyperModel(), objective=\"val_accuracy\", seed=42, max_epochs=10, factor=3, \n",
    "    hyperband_iterations=2, overwrite=True, directory=\"my_fashion_mnist\", project_name=\"hyperband\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5f02f85-e397-4968-bc58-998f044fe951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('my_logs/run_2024_06_17_16_05_15')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import strftime\n",
    "\n",
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "    return Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e32815a6-58a1-4677-9cc1-9644b391e365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 01m 00s]\n",
      "val_accuracy: 0.8222000002861023\n",
      "\n",
      "Best val_accuracy So Far: 0.8626000285148621\n",
      "Total elapsed time: 00h 17m 14s\n"
     ]
    }
   ],
   "source": [
    "# we'll run the hyperband tuner using the TensorBoard callback.\n",
    "from pathlib import Path\n",
    "\n",
    "root_logdir = Path(hyperband_tuner.project_dir) / \"tensorboard\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(root_logdir)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "hyperband_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbad339-e9ed-4c78-b543-9ed65707b0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
