{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling / Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasons for Feature Scaling include:-\n",
    "\n",
    "#### Improved Convergence.\n",
    "- Algorithms like gradient descent converge faster when features are scaled, unscaled features cause gradients to be very different in magnitude, leading to zigzag paths towards the minimum during oprimization.\n",
    "\n",
    "#### Equal Treatment of Features:\n",
    "- Algorithms such as KNN and SVMs are sensitive allowing for larger scales to disproportionately influence the results, leading to biased models.\n",
    "- Rescaling ensures that each feature contributes equally to the model.\n",
    "\n",
    "#### Enhanced Model Interpretability:\n",
    "- Model coefficients and weights can be more easily interpreted as they correspond to features of similar magnitude.\n",
    "\n",
    "#### Stabilized Training:\n",
    "- Neural Networks v=benefit from feature scaling as it helps prevent the network from becoming unstable due to large values in the input data.\n",
    "\n",
    "#### Compatibility with Regularizatio:\n",
    "- Regularization techniques like Lasso / rigde regression are affected by feature scales, regularization ensures tha regularization penalties are applied uniformly across all features.\n",
    "\n",
    "- Common rescaling methods include min-ma scaling, z-score normalization and max-abs scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28578564],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will create a feature.\n",
    "feature = np.array([[-500.5],\n",
    "                    [-100.0],\n",
    "                    [0],\n",
    "                    [100.1],\n",
    "                    [900.9]])\n",
    "\n",
    "# create scaler\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1)) \n",
    "# goal of the Min-Max scaling is to transform the features so they are within a specific range i.e (0, 1) in this case.\n",
    "\n",
    "# Scaling he feature.\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "# if we used fit only the min and max calculations would have been done and stores separately.\n",
    "# the transform is then used to change the original values and rescale them\n",
    "# fit_transform does both at the same time.\n",
    "\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score / Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing a Feature / Z-score.\n",
    "\n",
    "x = np.array([[-1000.1],\n",
    "[-200.2],\n",
    "[500.5],\n",
    "[600.6],\n",
    "[9000.9]])\n",
    "\n",
    "# Create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# features will have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "# Transform the feature\n",
    "standardized = scaler.fit_transform(x)\n",
    "\n",
    "# Show feature\n",
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0\n",
      "Standard deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print mean and standard deviation\n",
    "print(\"Mean:\", round(standardized.mean()))\n",
    "print(\"Standard deviation:\", standardized.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standard Scaler works best for PCA but neural networks are better of with min-max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar to standard scaler only it uses the median and the quartile range to counter the negative effects of significant outliers.\n",
    "\n",
    "# Create scaler\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# Transform feature\n",
    "rubust = robust_scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "rubust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
